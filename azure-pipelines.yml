# Python package
# Create and test a Python package on multiple Python versions.
# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/python

trigger:
  branches:
    include:
    - master
    - dev/*
    - pr/*

jobs:
- job: UnitTest
  pool:
    vmImage: 'vs2017-win2016'
  steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.7'
      architecture: 'x64'

  - script: python -m pip install --upgrade pip && pip install tox
    displayName: 'Install dependencies'

  - script: python -m tox -e pywin-unit
    displayName: Run unit tests

- job: PostgresIntegrationTest
  pool:
    vmImage: 'vs2017-win2016'
  dependsOn: UnitTest

  steps:
  - pwsh: |
      $serviceName = Get-Service -Name postgresql*
      Set-Service -InputObject $serviceName -StartupType Automatic
      Start-Service -InputObject $serviceName

      createdb.exe -U postgres dbt
      psql.exe  -U postgres -c "CREATE ROLE root WITH PASSWORD 'password';"
      psql.exe  -U postgres -c "ALTER ROLE root WITH LOGIN;"
      psql.exe  -U postgres -c "GRANT CREATE, CONNECT ON DATABASE dbt TO root WITH GRANT OPTION;"
      psql.exe  -U postgres -c "CREATE ROLE noaccess WITH PASSWORD 'password' NOSUPERUSER;"
      psql.exe  -U postgres -c "ALTER ROLE noaccess WITH LOGIN;"
      psql.exe  -U postgres -c "GRANT CONNECT ON DATABASE dbt TO noaccess;"
    displayName: Install postgresql and set up database

  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.7'
      architecture: 'x64'

  - script: python -m pip install --upgrade pip && pip install tox
    displayName: 'Install dependencies'

  - script: python -m tox -e pywin-postgres
    displayName: Run integration tests

# These three are all similar except secure environment variables, which MUST be passed along to their tasks,
# but there's probably a better way to do this!
- job: SnowflakeIntegrationTest
  pool:
    vmImage: 'vs2017-win2016'
  dependsOn: PostgresIntegrationTest
  condition: and(succeeded(), ne(variables['SYSTEM.PULLREQUEST.ISFORK'], 'true'))
  steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.7'
      architecture: 'x64'

  - script: python -m pip install --upgrade pip && pip install tox
    displayName: 'Install dependencies'

  - script: python -m tox -e pywin-snowflake
    env:
      SNOWFLAKE_TEST_ACCOUNT: $(SNOWFLAKE_TEST_ACCOUNT)
      SNOWFLAKE_TEST_PASSWORD: $(SNOWFLAKE_TEST_PASSWORD)
      SNOWFLAKE_TEST_USER: $(SNOWFLAKE_TEST_USER)
      SNOWFLAKE_TEST_WAREHOUSE: $(SNOWFLAKE_TEST_WAREHOUSE)
      SNOWFLAKE_TEST_OAUTH_REFRESH_TOKEN: $(SNOWFLAKE_TEST_OAUTH_REFRESH_TOKEN)
      SNOWFLAKE_TEST_OAUTH_CLIENT_ID: $(SNOWFLAKE_TEST_OAUTH_CLIENT_ID)
      SNOWFLAKE_TEST_OAUTH_CLIENT_SECRET: $(SNOWFLAKE_TEST_OAUTH_CLIENT_SECRET)
    displayName: Run integration tests

- job: BigQueryIntegrationTest
  pool:
    vmImage: 'vs2017-win2016'
  dependsOn: PostgresIntegrationTest
  condition: and(succeeded(), ne(variables['SYSTEM.PULLREQUEST.ISFORK'], 'true'))
  steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.7'
      architecture: 'x64'
  - script: python -m pip install --upgrade pip && pip install tox
    displayName: 'Install dependencies'
  - script: python -m tox -e pywin-bigquery
    env:
      BIGQUERY_SERVICE_ACCOUNT_JSON: $(BIGQUERY_SERVICE_ACCOUNT_JSON)
    displayName: Run integration tests

- job: RedshiftIntegrationTest
  pool:
    vmImage: 'vs2017-win2016'
  dependsOn: PostgresIntegrationTest
  condition: and(succeeded(), ne(variables['SYSTEM.PULLREQUEST.ISFORK'], 'true'))
  steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.7'
      architecture: 'x64'

  - script: python -m pip install --upgrade pip && pip install tox
    displayName: 'Install dependencies'

  - script: python -m tox -e pywin-redshift
    env:
      REDSHIFT_TEST_DBNAME: $(REDSHIFT_TEST_DBNAME)
      REDSHIFT_TEST_PASS: $(REDSHIFT_TEST_PASS)
      REDSHIFT_TEST_USER: $(REDSHIFT_TEST_USER)
      REDSHIFT_TEST_PORT: $(REDSHIFT_TEST_PORT)
      REDSHIFT_TEST_HOST: $(REDSHIFT_TEST_HOST)
    displayName: Run integration tests

- job: BuildWheel
  pool:
    vmImage: 'vs2017-win2016'
  dependsOn:
    - UnitTest
    - PostgresIntegrationTest
    - RedshiftIntegrationTest
    - SnowflakeIntegrationTest
    - BigQueryIntegrationTest
  condition: and(succeeded(), ne(variables['SYSTEM.PULLREQUEST.ISFORK'], 'true'))
  steps:
    - task: UsePythonVersion@0
      inputs:
        versionSpec: '3.7'
        architecture: 'x64'
    - script: python -m pip install --upgrade pip setuptools && python -m pip install -r requirements.txt && python -m pip install -r dev_requirements.txt
      displayName: Install dependencies
    - task: ShellScript@2
      inputs:
        scriptPath: scripts/build-wheels.sh
    - task: CopyFiles@2
      inputs:
        contents: 'dist\?(*.whl|*.tar.gz)'
        TargetFolder: '$(Build.ArtifactStagingDirectory)'
    - task: PublishBuildArtifacts@1
      inputs:
        pathtoPublish: '$(Build.ArtifactStagingDirectory)'
        artifactName: dists
